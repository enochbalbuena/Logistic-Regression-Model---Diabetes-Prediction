{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7992610,"sourceType":"datasetVersion","datasetId":4705451}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Unraveling the Links Between Physical Characteristics and Diabetes\n\n## Introduction\nAs I embarked on my journey into the realm of data analysis, I was driven by curiosity and a desire to make a tangible impact. For my inaugural project, I chose a topic close to many hearts: understanding diabetes. Specifically, my goal was to explore which physical characteristics are most closely associated with the likelihood of having diabetes.\n\nDiabetes is a condition that affects millions worldwide, with its management and prevention rooted deeply in understanding the risk factors. Among these, physical characteristics such as Body Mass Index (BMI), glucose levels, blood pressure, and others play important roles. With a dataset at hand that encapsulates these features among individuals, my mission was to analyze this data to uncover patterns and relationships that could that could help explain diabetes.\n\n#### Project Aim:\n\n* **To Identify Key Physical Characteristics**: I aimed to dive into the dataset and figure out which specific physical traits have the most significant relationships with diabetes (feature importance).\n* **To Develop a Predictive Model**: The heart of this project was to craft a model that could use information about these physical traits to predict whether an individual has diabetes. \n\nArmed with tools for exploratory data analysis, statistical insights, and machine learning, I set out on this adventure. This project was not just about applying what I had learned in tutorials and courses; it was about piecing together a story from data, about real people and real lives affected by diabetes.\n\nThrough this exploration, I hoped to not only hone my skills as an emerging data analyst but also to contribute, in some small way, to the broader dialogue on health and wellness. Join me as we step through the process of transforming raw data into insights and predictions, learning and growing with each figure and formula.","metadata":{}},{"cell_type":"markdown","source":"## Importing Necessary Libraries and Tools\nBy combining these tools, we're equipped to tackle our project from start to finish: from preparing and exploring our data, through building and tuning our model, to evaluating its performance.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import GridSearchCV\nimport numpy as np\nfrom sklearn.metrics import roc_curve, auc","metadata":{"execution":{"iopub.status.busy":"2024-04-06T23:17:17.282436Z","iopub.execute_input":"2024-04-06T23:17:17.282864Z","iopub.status.idle":"2024-04-06T23:17:17.291353Z","shell.execute_reply.started":"2024-04-06T23:17:17.282829Z","shell.execute_reply":"2024-04-06T23:17:17.289953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory data analysis","metadata":{}},{"cell_type":"markdown","source":"## Loading the dataset","metadata":{}},{"cell_type":"code","source":"\n# Load the dataset into a DataFrame\nurl = \"/kaggle/input/diabetes-intermediate-dataset/Diabetes.csv\"\ndf = pd.read_csv(url)\n\n# Display the first few rows of the dataset to understand its structure\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T23:17:17.293739Z","iopub.execute_input":"2024-04-06T23:17:17.294815Z","iopub.status.idle":"2024-04-06T23:17:17.329317Z","shell.execute_reply.started":"2024-04-06T23:17:17.294779Z","shell.execute_reply":"2024-04-06T23:17:17.328146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once the dataset has been successfully loaded, we can see a brief overview of its structure:\n\nThere are eight predictor variables: **Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction**, and **Age**.\n\nThe target variable is **Outcome**, which indicates whether or not an individual has diabetes (1 for positive, 0 for negative).\n\nIt appears there may already be missing or placeholder values (e.g., 0 for Insulin and SkinThickness could indicate missing data, since these measurements would not realistically be zero).\n\nWe'll generate some summary statistics for the numerical features and check for missing values to better understand the data's distribution and identify any potential issues we need to address.","metadata":{}},{"cell_type":"code","source":"# Summary statistics for the numerical features\nsummary_statistics = df.describe()\n\n# Checking for missing values\nmissing_values = df.isnull().sum()\n\nsummary_statistics, missing_values","metadata":{"execution":{"iopub.status.busy":"2024-04-06T23:17:17.331031Z","iopub.execute_input":"2024-04-06T23:17:17.331453Z","iopub.status.idle":"2024-04-06T23:17:17.375668Z","shell.execute_reply.started":"2024-04-06T23:17:17.331416Z","shell.execute_reply":"2024-04-06T23:17:17.372579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The summary statistics and missing value check provide us with several insights:\n\n### Summary Statistics:\n**Pregnancies**: The range is from 0 to 17, which is plausible. The average number of pregnancies per participant is approximately 3.85.\n\n**Glucose, BloodPressure, SkinThickness, Insulin, BMI**: These columns have a minimum value of 0, which is likely indicative of missing or placeholder values, especially for Glucose, BloodPressure, Insulin, and BMI, as these cannot realistically be zero.\nDiabetesPedigreeFunction and Age seem to have reasonable ranges with no immediate indication of placeholder values.\n\n### Missing Values:\nThe dataset does not contain any NaN values; however, the presence of 0s in certain columns (such as Glucose, BloodPressure, SkinThickness, Insulin, and BMI) might actually indicate missing data that needs to be handled.\nGiven these findings, the next steps would be handling the missing values. For columns where a value of 0 is not plausible, we will impute these values, either by replacing them with the mean/median of the column or using another imputation method.\n\nGiven the nature of our dataset, median imputation might be a sensible choice for Glucose, BloodPressure, SkinThickness, Insulin, and BMI, as these features are likely to be skewed due to the presence of very high or very low values (for example, high insulin levels in some diabetic patients). We'll proceed with median imputation for these columns. We'll replace 0s with the median value of each column, excluding the 0s from the calculation of the median.","metadata":{}},{"cell_type":"code","source":"# Columns to impute\ncolumns_to_impute = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n\n# Perform median imputation, replacing 0s with the median of each column (excluding 0s)\nfor column in columns_to_impute:\n    median_value = df[df[column] != 0][column].median()\n    df[column] = df[column].replace(0, median_value)\n\n# Display summary statistics again to verify changes\ndf[columns_to_impute].describe()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T23:17:17.377985Z","iopub.execute_input":"2024-04-06T23:17:17.378348Z","iopub.status.idle":"2024-04-06T23:17:17.416208Z","shell.execute_reply.started":"2024-04-06T23:17:17.378321Z","shell.execute_reply":"2024-04-06T23:17:17.414973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After applying the median imputation, here's a brief overview of the changes in summary statistics for the imputed columns:\n\n**Glucose, BloodPressure, SkinThickness, Insulin**, and **BMI** now have more plausible minimum values, indicating that the placeholder values of 0 have been replaced with the median of each respective column.\n\nThe mean and standard deviation for these columns have adjusted accordingly, providing a more accurate representation of the underlying data distribution.\nWith these adjustments, our dataset should be in a better state for analysis and modeling.\n\nThe next step in the exploratory analysis stage is to understand the data distribution and the relationship between features, especially in relation to the target variable, Outcome. We will start by examining the distribution of the numerical features and then move on to look at the correlation between features. This will help us identify which features are most strongly related to the target and may influence our feature selection and engineering steps later on.\n\nTo visualize the distribution of the numerical features, we'll create histograms for each. This will help us understand the shape of the data distribution (e.g., normal, skewed, bimodal) for each feature. Understanding the distribution is crucial for selecting appropriate preprocessing steps and models later on.\n\nAfter examining the distributions, we'll create a correlation matrix to see how the features relate to each other and, most importantly, how they relate to the Outcome variable. A high correlation with the Outcome variable may indicate a strong relationship that could be predictive of diabetes presence.","metadata":{}},{"cell_type":"code","source":"# Setting the aesthetics for the plots\nsns.set(style=\"whitegrid\")\n\n# Plotting histograms for the numerical features\ndf.hist(bins=20, figsize=(14, 10), grid=False)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T23:17:17.417569Z","iopub.execute_input":"2024-04-06T23:17:17.419381Z","iopub.status.idle":"2024-04-06T23:17:20.697124Z","shell.execute_reply.started":"2024-04-06T23:17:17.419348Z","shell.execute_reply":"2024-04-06T23:17:20.695912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The histograms provide a visual summary of the distribution of each numerical feature:\n\n* **Pregnancies**: Skewed to the right, indicating that fewer women have higher numbers of pregnancies.\n* **Glucose**: Appears to be normally distributed, which is expected as it's a primary measure for diagnosing diabetes.\n* **BloodPressure**: Also roughly normally distributed, with a few outliers on the lower end.\n* **SkinThickness**, **Insulin**: Both show right-skewed distributions, suggesting variability in the population regarding these measurements.\n* **BMI**: Slightly right-skewed, indicating that higher BMI values are less common but still present.\n* **DiabetesPedigreeFunction**: This is right-skewed, showing that higher pedigree function values are less common.\n* **Age**: Right-skewed, with a younger population being more prevalent in the dataset.\n\nNext, we'll examine the correlation matrix to identify potential relationships between features and the target variable Outcome. This will help us understand which features might be more important for predicting diabetes.","metadata":{}},{"cell_type":"code","source":"# Calculating the correlation matrix\ncorrelation_matrix = df.corr()\n\n# Plotting the correlation matrix as a heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\nplt.title(\"Correlation Matrix of Diabetes Dataset\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T23:17:20.698297Z","iopub.execute_input":"2024-04-06T23:17:20.698614Z","iopub.status.idle":"2024-04-06T23:17:21.368563Z","shell.execute_reply.started":"2024-04-06T23:17:20.698589Z","shell.execute_reply":"2024-04-06T23:17:21.367172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The heatmap of the correlation matrix highlights the relationships between features and the target variable, **Outcome**, as well as inter-feature correlations:\n\n* **Glucose** shows the highest correlation with **Outcome** (approximately 0.47), suggesting it's a significant predictor for diabetes presence, which aligns with medical knowledge.\n* **BMI**, **Age**, and **Pregnancies** also show moderate correlations with **Outcome**, indicating they could be useful predictors in our model.\n* **Insulin** and **SkinThickness** have lower but still notable correlations with **Outcome**.\n* The **DiabetesPedigreeFunction** has a moderate correlation, reinforcing its potential predictive value.\n\nNo feature shows an excessively high correlation with another (e.g., > 0.9), which means we don't have to worry too much about multicollinearity in our initial model.\n\nWith the exploratory analysis complete, we have a better understanding of our dataset's characteristics, including distribution of variables, missing value imputation, and feature correlations. This foundational knowledge is essential for the next steps: feature engineering and model selection.","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"Moving forward with preparing our data for the logistic regression model, we'll focus on two key steps:\n\n* **Feature Scaling**: Logistic regression can be sensitive to the scale of features. It's often beneficial to scale features to have a similar range, especially when using regularization. We'll use StandardScaler to standardize our features to have a mean of 0 and a standard deviation of 1.\n\n* **Data Splitting**: We'll split our dataset into training and testing sets. This allows us to train our model on one set of data and then test it on a separate set to evaluate its performance.\n\nLet's begin by standardizing our features and then splitting our data into training and test sets.","metadata":{}},{"cell_type":"code","source":"# Defining our features and target variable\nX = df.drop('Outcome', axis=1)\ny = df['Outcome']\n\n# Standardizing the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Splitting the dataset into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-06T23:17:21.370102Z","iopub.execute_input":"2024-04-06T23:17:21.370802Z","iopub.status.idle":"2024-04-06T23:17:21.390401Z","shell.execute_reply.started":"2024-04-06T23:17:21.370770Z","shell.execute_reply":"2024-04-06T23:17:21.389394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that the data has been successfully prepared for modeling:\n\n* We've standardized the features, ensuring they all have a mean of 0 and a standard deviation of 1.\n* The dataset was split into training and test sets, with 614 samples for training and 154 for testing.\n\nWith our data ready, we can now proceed to build and train our initial model, a logistic regression model. This step involves:\n\n**Model Training**: We'll train a logistic regression model using the training data.\n\n**Model Evaluation**: We'll evaluate the model's performance on the test set to understand its predictive capabilities.","metadata":{}},{"cell_type":"markdown","source":"# Model Creation and Evaluation\nWe want to start with a simple logistic regression model to be able to compare the models accuracy and the hyperparameter tuning effectiveness.","metadata":{}},{"cell_type":"code","source":"# Initializing the logistic regression model\nlog_reg = LogisticRegression(random_state=42)\n\n# Training the model\nlog_reg.fit(X_train, y_train)\n\n# Predicting the test set results\ny_pred = log_reg.predict(X_test)\n\n# Calculating the accuracy\naccuracy = accuracy_score(y_test, y_pred)\n\n# Generating the confusion matrix and classification report\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred)\n\naccuracy, conf_matrix, class_report","metadata":{"execution":{"iopub.status.busy":"2024-04-06T23:17:21.391700Z","iopub.execute_input":"2024-04-06T23:17:21.392122Z","iopub.status.idle":"2024-04-06T23:17:21.419355Z","shell.execute_reply.started":"2024-04-06T23:17:21.392095Z","shell.execute_reply":"2024-04-06T23:17:21.418028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The logistic regression model has been trained and evaluated on the test set, yielding an accuracy of approximately 75.3%. Here's a detailed breakdown of the model's performance:\n\n**Confusion Matrix**:\n\n* True Negatives (TN): 82\n* False Positives (FP): 17\n* False Negatives (FN): 21\n* True Positives (TP): 34\n\n\n**Classification Report**:\n\n* The precision for classifying non-diabetic instances (0) is 0.80, indicating a relatively high likelihood that individuals predicted as non-diabetic are correctly classified.\n* The recall for the non-diabetic class is 0.83, meaning that the model is able to identify 83% of the actual non-diabetic cases.\n* For the diabetic instances (1), the precision is 0.67, and the recall is 0.62, indicating moderate performance in correctly predicting diabetic cases.\n* The F1-scores, which balance precision and recall, are 0.81 for non-diabetic predictions and 0.64 for diabetic predictions, showing a decent performance of the model, especially for the non-diabetic class.\n\nThis performance is a good starting point, but there's room for improvement, especially in correctly identifying more diabetic instances (class 1) without significantly reducing the performance for non-diabetic instances (class 0).","metadata":{}},{"cell_type":"markdown","source":"# Hyperparameter Tuning\nWe're going to explore hyperparameter tuning for the logistic regression model to see if we can enhance its performance.\n\nOne effective method for tuning is using Grid Search with Cross-Validation. This approach tests a range of hyperparameter values to find the combination that results in the best model performance.\n\nFor logistic regression, we'll focus on tuning the following hyperparameters:\n\n* **C**: Inverse of regularization strength; smaller values specify stronger regularization.\n* **penalty**: Specifies the norm used in the penalization (e.g., \"l1\", \"l2\").\nWe'll use cross-validation to ensure that our model's performance is robust across different subsets of the training data. Let's start the hyperparameter tuning process using Grid Search CV.","metadata":{}},{"cell_type":"code","source":"# Defining the parameter grid\nparam_grid = {\n    'C': [0.01, 0.1, 1, 10, 100],\n    'penalty': ['l1', 'l2'],\n    'solver': ['liblinear']  # 'liblinear' works well with l1 and l2 penalties\n}\n\n# Initializing the Grid Search with cross-validation\ngrid_search = GridSearchCV(LogisticRegression(random_state=42), param_grid, cv=5, scoring='accuracy', verbose=0)\n\n# Fitting Grid Search to the data\ngrid_search.fit(X_train, y_train)\n\n# Best parameters and best score\nbest_params = grid_search.best_params_\nbest_score = grid_search.best_score_\n\nbest_params, best_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The hyperparameter tuning with Grid Search CV has identified the best parameters for the logistic regression model to be:\n\n* **C** (Inverse of regularization strength): 1\n* **Penalty** (Norm used in the penalization): l1\n* **Solver**: liblinear\n\nThe best cross-validation accuracy achieved with these parameters is approximately 77.0%, which is an improvement over the initial logistic regression model's accuracy.\n\nNext, we can evaluate this tuned model on the test set to see if we observe a similar improvement in performance.","metadata":{}},{"cell_type":"code","source":"# Retraining the model with the best parameters found\ntuned_log_reg = LogisticRegression(C=1, penalty='l1', solver='liblinear', random_state=42)\ntuned_log_reg.fit(X_train, y_train)\n\n# Predicting the test set results with the tuned model\ny_pred_tuned = tuned_log_reg.predict(X_test)\n\n# Calculating the accuracy of the tuned model\naccuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n\n# Generating the confusion matrix and classification report for the tuned model\nconf_matrix_tuned = confusion_matrix(y_test, y_pred_tuned)\nclass_report_tuned = classification_report(y_test, y_pred_tuned)\n\naccuracy_tuned, conf_matrix_tuned, class_report_tuned","metadata":{"execution":{"iopub.status.busy":"2024-04-06T23:17:21.651042Z","iopub.execute_input":"2024-04-06T23:17:21.651486Z","iopub.status.idle":"2024-04-06T23:17:21.677269Z","shell.execute_reply.started":"2024-04-06T23:17:21.651446Z","shell.execute_reply":"2024-04-06T23:17:21.676434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After hyperparameter tuning, the logistic regression model has achieved an accuracy of approximately 75.3% on the test set, which matches the performance of the initial model before tuning. The confusion matrix and classification report also indicate similar performance metrics:\n\n**Confusion Matrix**:\n\n* True Negatives (TN): 82\n* False Positives (FP): 17\n* False Negatives (FN): 21\n* True Positives (TP): 34\n\n**Classification Report**:\n\n* Precision for the non-diabetic class (0) remains at 0.80, and the recall is 0.83.\n* For the diabetic class (1), the precision is 0.67, and the recall is 0.62.\n* The F1-scores are 0.81 for non-diabetic predictions and 0.64 for diabetic predictions.\n\nThe results suggest that while hyperparameter tuning selected the best parameters within the tested range, the overall performance improvement on the test set is minimal. This outcome underscores the limitations of logistic regression for this dataset and the potential need for more complex models to capture the underlying patterns more effectively.","metadata":{}},{"cell_type":"markdown","source":"## Feature Importance Plot\nIn our journey to predict diabetes, we found out that not all information (or features) holds the same weight. Some bits of information, like a person's Glucose level or BMI, can tell us more about the likelihood of having diabetes than others, such as their age or number of pregnancies.\n\nThe feature importance plot is a visual tool that helps us see which features matter most. In the plot, each bar represents a feature: the longer the bar, the more influence it has.","metadata":{}},{"cell_type":"code","source":"# Assuming 'tuned_log_reg' is your tuned logistic regression model and 'X' is your feature DataFrame\nfeature_importance = tuned_log_reg.coef_[0]\nfeatures = X.columns\nindices = np.argsort(np.abs(feature_importance))[::-1]\n\nplt.figure(figsize=(10, 6))\nplt.title(\"Feature Importance in Logistic Regression Model\")\nplt.bar(range(len(indices)), feature_importance[indices], align=\"center\")\nplt.xticks(range(len(indices)), features[indices], rotation=45)\nplt.ylabel(\"Coefficient Magnitude\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T23:17:21.678739Z","iopub.execute_input":"2024-04-06T23:17:21.679056Z","iopub.status.idle":"2024-04-06T23:17:22.045465Z","shell.execute_reply.started":"2024-04-06T23:17:21.679031Z","shell.execute_reply":"2024-04-06T23:17:22.044338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ROC Curve and AUC Score\nThe ROC curve is a graph where we plot two rates against each other at various thresholds: the rate at which we correctly predict diabetes (True Positive Rate) versus the rate at which we incorrectly predict it (False Positive Rate).\n\nThe ROC curve shows how often I'd be right (or wrong) at different levels of cautiousness (thresholds). The closer this curve gets to the top-left corner, the better my predictions are.\n\nThe AUC score is like a report card grade for the ROC curve, telling us overall how good the model is at predicting diabetes - from \"just guessing\" (0.5) to \"always spot on\" (1.0). My model’s score tells me it’s quite reliable, and that's a win for my first project!","metadata":{}},{"cell_type":"code","source":"# Predict probabilities\ny_pred_proba = tuned_log_reg.predict_proba(X_test)[:, 1]\n\n# Calculate ROC curve and AUC\nfpr, tpr, _ = roc_curve(y_test, y_pred_proba)\nroc_auc = auc(fpr, tpr)\n\n# Plotting\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T23:17:22.046965Z","iopub.execute_input":"2024-04-06T23:17:22.048115Z","iopub.status.idle":"2024-04-06T23:17:22.379235Z","shell.execute_reply.started":"2024-04-06T23:17:22.048075Z","shell.execute_reply":"2024-04-06T23:17:22.378067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\nIn this project, we embarked on a journey to predict diabetes outcomes using various data analysis and machine learning techniques. Starting with exploratory data analysis, we gained insights into the dataset, uncovering the distribution of features and their relationships with the target variable. Our initial model, a logistic regression classifier, set a strong baseline with an accuracy of approximately 75.3%. Through hyperparameter tuning, we refined this model, maintaining its robustness without compromising on interpretability.\n\nDespite exploring hyperparameter tuning techniques, the improvements in predictive performance were marginal. This observation led us to a pivotal realization: the power of simplicity. The logistic regression model, with its interpretability and direct approach, proved to be incredibly effective for this task despite its limitations, demonstrating that complexity does not always equate to superior performance.\n\nTo visually underscore our findings, we examined the feature importance within our logistic regression model, revealing that Glucose levels, among others, hold significant predictive power. This aligns with medical understanding, emphasizing the model's practical relevance. Additionally, plotting the ROC curve offered a comprehensive view of our model's performance across various thresholds, reinforcing its effectiveness in distinguishing between outcomes.\n\nIn conclusion, this project not only enhanced our understanding of diabetes prediction but also reinforced the value of methodical exploratory data analysis, and the power of simple models. Moving forward, these insights will serve as a cornerstone for further research, potentially incorporating more domain-specific knowledge and data to refine our predictive capabilities.","metadata":{}}]}